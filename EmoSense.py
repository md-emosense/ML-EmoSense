# -*- coding: utf-8 -*-
"""Emotion Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N0Az7X0sQQhF4ANhXlaVYYRxBbWQhqYm

# Emotion Detection Project

# Dataset
"""

!pip install gdown

# import requires packages
import gdown
import zipfile
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""Download file from gdrive"""

#Define file ID from Gdrive and the destination path
file_id = '1d1yWPJZ7W_EGB2HS31VWHcSGX8KwkSIr'
destination = '/content/facerecog.zip'

#download file
gdown.download(f'https://drive.google.com/uc?export=download&id={file_id}', destination, quiet=False)

"""Extract the zip file"""

#define the extraction path
extraction_path = '/content/facerecog'

#Create the extraction directory if it doesn't exist
os.makedirs(extraction_path, exist_ok=True)

# Extract the contents of the ZIP file
with zipfile.ZipFile(destination, 'r') as zip_ref:
    zip_ref.extractall(extraction_path)

# List the files in the extraction directory to verify
print(os.listdir(extraction_path))

"""Access tree folder"""

# List the contents of the parent directory
contents = os.listdir(extraction_path)

# Iterate over the contents to find subdirectories
for item in contents:
    # Check if the item is a directory
    if os.path.isdir(os.path.join(extraction_path, item)):
        print(f"Found subdirectory: {item}")

        # Define the path to the subdirectory
        subdirectory_path = os.path.join(extraction_path, item)

"""Create a train and test path"""

# Define the path to the images directory
images_directory = '/content/facerecog/images'

# Define paths for train and test directories
train_directory = os.path.join(images_directory, 'train')
val_directory = os.path.join(images_directory, 'validation')

# List the contents of the train directory
train_contents = os.listdir(train_directory)
print("Contents of train directory:", train_contents)

# List the contents of the test directory
val_contents = os.listdir(val_directory)
print("Contents of test directory:", val_contents)

"""Data Analysis"""

# The function returns a DataFrame with these counts, indexed by a specified set name (e.g., 'train' or 'test').
def count_files_in_subdirs(directory, set_name):
    # Initialize an empty dictionary to hold the count of files for each subdirectory.
    counts = {}

    # Iterate over each item in the given directory.
    for item in os.listdir(directory):
        # Construct the full path to the item.
        item_path = os.path.join(directory, item)

        # Check if the item is a directory.
        if os.path.isdir(item_path):
            # Count the number of files in the subdirectory and add it to the dictionary.
            counts[item] = len(os.listdir(item_path))

    # Convert the counts dictionary to a DataFrame for easy viewing and analysis.
    # The index of the DataFrame is set to the provided set name.
    df = pd.DataFrame(counts, index=[set_name])
    return df

# Count the files in the subdirectories of the training directory and print the result.
train_count = count_files_in_subdirs(train_directory, 'train')
print(train_count)

# Count the files in the subdirectories of the testing directory and print the result.
val_count = count_files_in_subdirs(val_directory, 'validation')
print(val_count)

# Function to print files in a directory
def print_files(directory):
    print("Contents of", directory)
    for root, dirs, files in os.walk(directory):
        for file in files:
            print(os.path.join(root, file))

# Print files in train directory
print_files(train_directory)

# Print files in validation directory
print_files(val_directory)

"""# Image Processsing"""

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
validation_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Preprocess all train images
train_generator = train_datagen.flow_from_directory(
    train_directory,
    target_size=(48, 48),
    batch_size=64,
    color_mode='grayscale',
    class_mode='categorical'
)

# Preprocess all validation images
val_generator = validation_datagen.flow_from_directory(
    val_directory,
    target_size=(48, 48),
    batch_size=64,
    color_mode='grayscale',
    class_mode='categorical'
)

"""Display a few example of images"""

emotions = os.listdir(train_directory)
plt.figure(figsize=(15, 10))

for i, emotion in enumerate(emotions, 1):
    folder = os.path.join(train_directory, emotion)
    img_path = os.path.join(folder, os.listdir(folder)[0])
    img = plt.imread(img_path)
    plt.subplot(3, 4, i)
    plt.imshow(img, cmap='gray')
    plt.title(emotion)
    plt.axis('off')

"""# Create Model Structure using CNN"""

from tensorflow.keras import layers, models, regularizers, optimizers
from tensorflow.keras.applications import VGG16, ResNet50V2
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense, Activation, GlobalAveragePooling2D
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam, Adamax
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from keras.utils import plot_model

# Labeling Data
# Accessing class labels for the training data
train_class_labels = train_generator.class_indices
print("Training class labels:", train_class_labels)

# Accessing class labels for the validation data
validation_class_labels = val_generator.class_indices
print("Validation class labels:", validation_class_labels)

model = tf.keras.Sequential([
    # Adding convolutional layers with activations on the same line for clarity
    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), kernel_initializer="glorot_uniform", padding='same', input_shape=(48, 48, 1)),
    tf.keras.layers.Activation('relu'),

    tf.keras.layers.Conv2D(64, kernel_size=(3, 3), padding='same'),
    tf.keras.layers.Activation('relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Dropout(0.25),

    tf.keras.layers.Conv2D(128, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l2(0.01)),
    tf.keras.layers.Activation('relu'),

    tf.keras.layers.Conv2D(256, kernel_size=(3, 3), kernel_regularizer=regularizers.l2(0.01)),
    tf.keras.layers.Activation('relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Dropout(0.25),

    tf.keras.layers.Conv2D(512, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l2(0.01)),
    tf.keras.layers.Activation('relu'),

    tf.keras.layers.Conv2D(512, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l2(0.01)),
    tf.keras.layers.Activation('relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Dropout(0.25),

    # Flattening and adding dense layers
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1024),
    tf.keras.layers.Activation('relu'),
    tf.keras.layers.Dropout(0.5),

    # Output layer
    tf.keras.layers.Dense(7),
    tf.keras.layers.Activation('softmax')
])

# Display the model summary
model.summary()

# Compiling the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

from tensorflow.keras import regularizers

# Assuming your model is already defined as mentioned
# Ensure you have the following imports if not already done:
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense

# Adjust number of epochs
epochs = 100

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=val_generator,
    validation_steps=val_generator.samples // val_generator.batch_size,
    epochs=epochs
)

"""Evaluating Accuracy and Loss for the Model"""

#sets for each training epoch
accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

#get number of epochs
epochs = range(len(accuracy))

#plot training and validation accuracy per epoch
plt.plot  ( epochs,     accuracy, label='Training')
plt.plot  ( epochs, val_accuracy, label='Validation')
plt.title ('Training and validation accuracy')
plt.legend()
plt.figure()

#plot training and validation loss per epoch
plt.plot  ( epochs,     loss, label='Training')
plt.plot  ( epochs, val_loss, label='Validation')
plt.legend()
plt.title ('Training and validation loss')

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(val_generator)
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")

"""Save Model"""

saved_model_path = "./emosense_model.h5"
model.save(saved_model_path)

"""Convert to TFjs"""

! tensorflowjs_converter \
  --input_format=keras \
  {saved_model_path} \
  "./model.json"